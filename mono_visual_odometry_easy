#port from https://github.com/yueying/LearningVO

### References
#1. [一个简单的视觉里程计实现 | 冯兵的博客](http://fengbing.net/2015/07/26/%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E8%A7%86%E8%A7%89%E9%87%8C%E7%A8%8B%E8%AE%A1%E5%AE%9E%E7%8E%B01/ )<br>
#2. [Monocular Visual Odometry using OpenCV](http://avisingh599.github.io/vision/monocular-vo/) and 
#its related project report [_Monocular Visual Odometry_](http://avisingh599.github.io/assets/ugp2-report.pdf) | Avi Singh
#Search "cv2.findEssentialMat", "cv2.recoverPose" etc. in github, you'll find more python projects on slam / visual odometry / 3d reconstruction

import numpy as np 
import cv2

STAGE_FIRST_FRAME = 0
STAGE_SECOND_FRAME = 1
STAGE_DEFAULT_FRAME = 2
kMinNumFeature = 1500

lk_params = dict(winSize  = (21, 21), 
		#winSize表示选择多少个点进行u和v的求解	#maxLevel = 3,
             	criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01))

def featureTracking(image_ref, image_cur, px_ref):

    kp2, st, err = cv2.calcOpticalFlowPyrLK(image_ref, image_cur, px_ref, None, **lk_params)
    ## calcOpticalFlowPyrLK 用于获得光流检测后的角点位置
    ## 参数说明：pl表示光流检测后的角点位置，
    ## st表示是否是运动的角点，
    ## err表示是否出错，
    ## old_gray表示输入前一帧图片，
    ## frame_gray表示后一帧图片，
    ## p0表示需要检测的角点，
    ## lk_params：winSize表示选择多少个点进行u和v的求解，
    ## maxLevel表示空间金字塔的层数

    ## shape: [k,2] [k,1] [k,1]
    # reshape命令，在不知道数组维数的情况下，对其变换维数
    st = st.reshape(st.shape[0])

    kp1 = px_ref[st == 1]
    kp2 = kp2[st == 1]

    return kp1, kp2


class PinholeCamera:
    def __init__(self, width, height, fx, fy, cx, cy, 
                            k1=0.0, k2=0.0, p1=0.0, p2=0.0, k3=0.0):
        self.width = width
        self.height = height
        self.fx = fx
        self.fy = fy
        self.cx = cx
        self.cy = cy
        self.distortion = (abs(k1) > 0.0000001)
        self.d = [k1, k2, p1, p2, k3]


class VisualOdometry:
    def __init__(self, cam, annotations):
    #cam是PinholeCamera()
    #annotations是真实轨迹的路径
        self.frame_stage = 0
        self.cam = cam
        self.new_frame = None
        self.last_frame = None
        self.cur_R = None
        self.cur_t = None
        self.px_ref = None
        self.px_cur = None
        self.focal = cam.fx
        self.pp = (cam.cx, cam.cy)
        self.trueX, self.trueY, self.trueZ = 0, 0, 0#设定真实轨迹初值

        #使用 FAST 检测角点
        self.detector = cv2.FastFeatureDetector_create(threshold=25, nonmaxSuppression=True)

        #使用ORB计算角点
        #orb = cv2.ORB_create()
        #kp = orb.detect(img,None)
        #kp,des= orb.compute(img, kp)
        
        with open(annotations) as f:
                self.annotations = f.readlines()

    def getAbsoluteScale(self, frame_id):
        #specialized for KITTI odometry dataset
        #为 KITTI 数据集实例化
        
        ss = self.annotations[frame_id-1].strip().split()
        x_prev = float(ss[3])
        y_prev = float(ss[7])
        z_prev = float(ss[11])
        
        ss = self.annotations[frame_id].strip().split()
        x = float(ss[3])
        y = float(ss[7])
        z = float(ss[11])
        
        self.trueX, self.trueY, self.trueZ = x, y, z
        return np.sqrt((x - x_prev)*(x - x_prev) + (y - y_prev)*(y - y_prev) + (z - z_prev)*(z - z_prev))

    def processFirstFrame(self): #处理第一帧
        self.px_ref = self.detector.detect(self.new_frame)
        self.px_ref = np.array([x.pt for x in self.px_ref], dtype=np.float32)
        self.frame_stage = STAGE_SECOND_FRAME

    def processSecondFrame(self): #处理第二帧
        self.px_ref, self.px_cur = featureTracking(self.last_frame, self.new_frame, self.px_ref)
        E, mask = cv2.findEssentialMat(self.px_cur, self.px_ref, focal=self.focal, pp=self.pp, method=cv2.RANSAC, prob=0.999, threshold=1.0)
        
        ## Mat findEssentialMat( InputArray points1, InputArray points2,
        ##                      InputArray cameraMatrix, int method = RANSAC,
        ##                      double prob = 0.999, double threshold = 1.0,
        ##                      OutputArray mask = noArray() );
        ## 功能  从两幅图像中的相应点计算一个基本矩阵.
        ## points1第一幅图片的N个二维像素点. 点坐标应该是浮点（单精度或双精度）。
        ## points2 第二幅图片的二维像素点，与points1同样大小和类型 .
        ## cameraMatrix相机矩阵，请注意，此功能假设points1和points2是具有相同摄像机矩阵的摄像机的特征点。
        ## method计算本征矩阵的方法- ** RANSAC **用于RANSAC算法。- ** LMedS **用于LMedS算法。

        _, self.cur_R, self.cur_t, mask = cv2.recoverPose(E, self.px_cur, self.px_ref, focal=self.focal, pp = self.pp)
        self.frame_stage = STAGE_DEFAULT_FRAME
        self.px_ref = self.px_cur


    def processFrame(self, frame_id):
        self.px_ref, self.px_cur = featureTracking(self.last_frame, self.new_frame, self.px_ref)
        
        E, mask = cv2.findEssentialMat(self.px_cur, self.px_ref, focal=self.focal, pp=self.pp, method=cv2.RANSAC, prob=0.999, threshold=1.0)
        
        _, R, t, mask = cv2.recoverPose(E, self.px_cur, self.px_ref, focal=self.focal, pp = self.pp)
        
        absolute_scale = self.getAbsoluteScale(frame_id)
        if(absolute_scale > 0.1):
                self.cur_t = self.cur_t + absolute_scale*self.cur_R.dot(t) 
                self.cur_R = R.dot(self.cur_R)
                
        if(self.px_ref.shape[0] < kMinNumFeature):
                self.px_cur = self.detector.detect(self.new_frame)
                self.px_cur = np.array([x.pt for x in self.px_cur], dtype=np.float32)
                
        self.px_ref = self.px_cur

    def update(self, img, frame_id):
        assert(img.ndim==2 and img.shape[0]==self.cam.height and img.shape[1]==self.cam.width),\
        "提供的图像和相机模型的大小不一致或者图像不是灰度图像"
        #assert 其作用是如果它的条件返回错误，则终止程序执行
        
        self.new_frame = img
        if(self.frame_stage == STAGE_DEFAULT_FRAME):
                self.processFrame(frame_id)
        elif(self.frame_stage == STAGE_SECOND_FRAME):
                self.processSecondFrame()
        elif(self.frame_stage == STAGE_FIRST_FRAME):
                self.processFirstFrame()
        self.last_frame = self.new_frame
